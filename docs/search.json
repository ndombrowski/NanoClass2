[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NanoClass2",
    "section": "",
    "text": "NanoClass2 is a taxonomic meta-classifier for 16S/18S amplicon sequencing data generated with the Oxford Nanopore MinION. The first iteration of this workflow, NanoClass, was originally developed by Evelien Jongepier and the original version can be found here.\nWith a single command, you can run upto 11 classification tools on multiple samples in parallel, including BLASTN, Centrifuge, Kraken2, IDTAXA, MegaBLAST, dcMegaBLAST, Minimap2, Mothur, QIIME2, RDP and SPINGO. Read preparation steps, such as quality trimming, length filtering and sub-sampling, are an integral part of the pipeline.\nNanoClass automatically installs all software packages and dependencies, downloads and builds required taxonomic databases and runs the analysis on your samples.\n\n\n\n\n\n\nImportant\n\n\n\nNanoClass is using Kraken2 as one of the classifiers but users have noticed that when using older Kraken versions there is a problem when downloading the Silva database.\nWe plan to make kraken2 available again but since this means updating the used Silva database throughout the workflow this is still in progress. For now, we recommend running this workflow without Kraken2 if you setup NanoClass2 for the first time."
  },
  {
    "objectID": "index.html#nanoclass2",
    "href": "index.html#nanoclass2",
    "title": "NanoClass2",
    "section": "",
    "text": "NanoClass2 is a taxonomic meta-classifier for 16S/18S amplicon sequencing data generated with the Oxford Nanopore MinION. The first iteration of this workflow, NanoClass, was originally developed by Evelien Jongepier and the original version can be found here.\nWith a single command, you can run upto 11 classification tools on multiple samples in parallel, including BLASTN, Centrifuge, Kraken2, IDTAXA, MegaBLAST, dcMegaBLAST, Minimap2, Mothur, QIIME2, RDP and SPINGO. Read preparation steps, such as quality trimming, length filtering and sub-sampling, are an integral part of the pipeline.\nNanoClass automatically installs all software packages and dependencies, downloads and builds required taxonomic databases and runs the analysis on your samples."
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "NanoITS",
    "section": "Quick start",
    "text": "Quick start\n…"
  },
  {
    "objectID": "source/code_dev.html",
    "href": "source/code_dev.html",
    "title": "NanoClass2",
    "section": "",
    "text": "wdir=\"/home/ndombro/personal/testing\"\ncd $wdir\n\n#setup snakemake env\n#mamba create -c conda-forge -c bioconda -n snakemake_nanoclass python=3.9.7 snakemake=6.8.0 tabulate=0.8\n\nconda activate snakemake_nanoclass\n\n\n\n\n\nmkdir input\n\n#get config \ncp ~/personal/snakemake_workflows/NanoClass2/config.yaml .\n\n#cp batch script\ncp ~/personal/snakemake_workflows/NanoClass2/jobscript.sh .\n\n#get mapping file\ncp ~/personal/snakemake_workflows/NanoClass2/example_files/mapping.csv .\n\nEdits:\n\nconfig.yaml:\n\nChange path to mapping.csv to mapping.csv\n\nChanges to mapping.csv:\n\nChange $PWD to /home/ndombro//personal/snakemake_workflows/NanoClass2/example_files/\n\njobscript.sh\n\nChange line with snakmake command to cmd=\"srun --cores $SLURM_CPUS_ON_NODE  snakemake -s ~/personal/snakemake_workflows/NanoClass2/Snakefile --configfile config.yaml --use-conda --conda-prefix ~/personal/snakemake_workflows/NanoClass2/.snakemake/conda --cores $SLURM_CPUS_ON_NODE --nolock --rerun-incomplete\"\n\n\n\n#dry run\nsrun --cores 1 snakemake -s ~/personal/snakemake_workflows/NanoClass2/Snakefile --configfile config.yaml --use-conda --conda-prefix ~/personal/snakemake_workflows/NanoClass2/.snakemake/conda --cores 1 --nolock --rerun-incomplete -np"
  },
  {
    "objectID": "source/code_dev.html#notes-on-code-development",
    "href": "source/code_dev.html#notes-on-code-development",
    "title": "NanoClass2",
    "section": "",
    "text": "wdir=\"/home/ndombro/personal/testing\"\ncd $wdir\n\n#setup snakemake env\n#mamba create -c conda-forge -c bioconda -n snakemake_nanoclass python=3.9.7 snakemake=6.8.0 tabulate=0.8\n\nconda activate snakemake_nanoclass\n\n\n\n\n\nmkdir input\n\n#get config \ncp ~/personal/snakemake_workflows/NanoClass2/config.yaml .\n\n#cp batch script\ncp ~/personal/snakemake_workflows/NanoClass2/jobscript.sh .\n\n#get mapping file\ncp ~/personal/snakemake_workflows/NanoClass2/example_files/mapping.csv .\n\nEdits:\n\nconfig.yaml:\n\nChange path to mapping.csv to mapping.csv\n\nChanges to mapping.csv:\n\nChange $PWD to /home/ndombro//personal/snakemake_workflows/NanoClass2/example_files/\n\njobscript.sh\n\nChange line with snakmake command to cmd=\"srun --cores $SLURM_CPUS_ON_NODE  snakemake -s ~/personal/snakemake_workflows/NanoClass2/Snakefile --configfile config.yaml --use-conda --conda-prefix ~/personal/snakemake_workflows/NanoClass2/.snakemake/conda --cores $SLURM_CPUS_ON_NODE --nolock --rerun-incomplete\"\n\n\n\n#dry run\nsrun --cores 1 snakemake -s ~/personal/snakemake_workflows/NanoClass2/Snakefile --configfile config.yaml --use-conda --conda-prefix ~/personal/snakemake_workflows/NanoClass2/.snakemake/conda --cores 1 --nolock --rerun-incomplete -np"
  },
  {
    "objectID": "source/installation_instructions.html",
    "href": "source/installation_instructions.html",
    "title": "Installation",
    "section": "",
    "text": "To be able to run this workflow you need conda or mamba installed. If you do not have either of these installed, check out the installation instruction for conda. Since July 2023 conda comes with mamba installed and should be available when updating conda to v23.10.0.\nIf you only want to install mamba, follow the instructions found here.\n\n\n\nThis workflow was developed using snakemake v6.8.0 and python3.9.7 and you might run into problems when using different version, which is why we recommend installing snakemake as follows:\n\nmamba create -c conda-forge -c bioconda -n snakemake_nanoclass python=3.9.7 snakemake=6.8.0 tabulate=0.8\n\n\n\n\nNanoClass can be installed via git as follows:\n\ngit clone https://github.com/ndombrowski/NanoClass2.git\n\nIf you don’t have or want to install git, you can also download NanoClass as follows&gt;\n\nGo to https://github.com/ndombrowski/NanoClass2\nClick the green code button\nDownload zip\nExtract zip"
  },
  {
    "objectID": "source/installation_instructions.html#install-condamamba",
    "href": "source/installation_instructions.html#install-condamamba",
    "title": "Installation",
    "section": "",
    "text": "To be able to run this workflow you need conda or mamba installed. If you do not have either of these installed, check out the installation instruction for conda. Since July 2023 conda comes with mamba installed and should be available when updating conda to v23.10.0.\nIf you only want to install mamba, follow the instructions found here."
  },
  {
    "objectID": "source/installation_instructions.html#install-snakemake",
    "href": "source/installation_instructions.html#install-snakemake",
    "title": "Installation",
    "section": "",
    "text": "This workflow was developed using snakemake v6.8.0 and python3.9.7 and you might run into problems when using different version, which is why we recommend installing snakemake as follows:\n\nmamba create -c conda-forge -c bioconda -n snakemake_nanoclass python=3.9.7 snakemake=6.8.0 tabulate=0.8"
  },
  {
    "objectID": "source/installation_instructions.html#install-nanoits",
    "href": "source/installation_instructions.html#install-nanoits",
    "title": "Installation",
    "section": "",
    "text": "NanoClass can be installed via git as follows:\n\ngit clone https://github.com/ndombrowski/NanoClass2.git\n\nIf you don’t have or want to install git, you can also download NanoClass as follows&gt;\n\nGo to https://github.com/ndombrowski/NanoClass2\nClick the green code button\nDownload zip\nExtract zip"
  },
  {
    "objectID": "index.html#general",
    "href": "index.html#general",
    "title": "NanoClass2",
    "section": "",
    "text": "NanoClass2 is a taxonomic meta-classifier for 16S/18S amplicon sequencing data generated with the Oxford Nanopore MinION. The first iteration of this workflow, NanoClass, was originally developed by Evelien Jongepier and the original version can be found here.\nWith a single command, you can run upto 11 classification tools on multiple samples in parallel, including BLASTN, Centrifuge, Kraken2, IDTAXA, MegaBLAST, dcMegaBLAST, Minimap2, Mothur, QIIME2, RDP and SPINGO. Read preparation steps, such as quality trimming, length filtering and sub-sampling, are an integral part of the pipeline.\nNanoClass automatically installs all software packages and dependencies, downloads and builds required taxonomic databases and runs the analysis on your samples.\n\n\n\n\n\n\nImportant\n\n\n\nNanoClass is using Kraken2 as one of the classifiers but users have noticed that when using older Kraken versions there is a problem when downloading the Silva database.\nWe plan to make kraken2 available again but since this means updating the used Silva database throughout the workflow this is still in progress. For now, we recommend running this workflow without Kraken2 if you setup NanoClass2 for the first time."
  },
  {
    "objectID": "source/run_nanoclass.html",
    "href": "source/run_nanoclass.html",
    "title": "Running NanoClass2",
    "section": "",
    "text": "NanoClass2 will take de-multiplexed and compressed fastq files as input and generate OTU tables and several summary statistics as output.\nTo run NanoClass2 please, provide a single fastq.gz file per sample.\nIf you have no preference for a classifier, you first might want to test, which classifier performs best on your data. NanoClass2 allows to test this by subsampling your dataset and running all 11 classification tools on this smaller subsample. Test on data sets of variable complexity have shown that a small subset of data is enough to assess tool performance. Once you have decided which tool or tools to use you can run these tools on your entire dataset.\n\n\nIn the configuration file, also called config.yaml, you can specify how NanoClass2 should be run.\nTo change the default settings and tell Snakemake where your data is located copy the config.yaml file found in the NanoClass2 folder to the folder in which you want to analyse your data, i.e. like this:\n\ncp &lt;path_to_NanoClass2_folder&gt;.config.yaml .\n\nYou can of course run your analyses in NanoITS folder you downloaded, but often its easier to separate software from analyses.\nNext, open the config.yaml with an editor, such as nano. There are several things you can modify:\n1. The samples you want to analyse\nHere, you need to provide the path to a comma-separated mapping file that describes the samples you want to analyse in the section: samples_file: \"example_files/mapping.csv\". You can provide the relative path (i.e. relative to the working directory you start the snakemake workflow in) or absolute path (i.e. the location of a file or directory from the root directory(/))\nThis file needs to contain the following columns:\n\nrun: The run name of your sample. This is useful if you want to run NanoClass several times on the same data but with different settings.\nsample: The names of your sample. This id will be used to label all files created in subsequent steps. Your sample names should be unique and only contain letters and numbers. Do not use other symbols, such as spaces, dots or underscores in your sample names.\nbarcode: The barcode ID. Can be empty as it is not actively used in the workflow as of now\npath: Path to the fastq.gz files. You can provide the relative or absolute path. The workflow accepts one file per barcode, so if you have more than one file merge these files first, for example using the cat command.\n\nAn example file could look like this (exchange  with the location of your samples):\nrun,sample,barcode,path\ndemo,R1A,BC01,&lt;path&gt;/barcode01_merged.fastq.gz\ndemo,R2A,BC02,&lt;path&gt;/barcode02_merged.fastq.gz\ndemo,R3A,BC03,&lt;path&gt;/barcode03_merged.fastq.gz\n2. The classifiers you want to use\nYou can choose what classifiers you want to use in methods: [\"blastn\",\"centrifuge\",\"dcmegablast\",\"idtaxa\",\"megablast\",\"minimap\",\"mothur\",\"qiime\",\"rdp\",\"spingo\"]. If you want to first compare different classifiers you can keep use the full list.\n3. Subsampling our reads\n\n\n\n\n\n\nImportant\n\n\n\nIn this section, we can specify whether we would like to subset the number of reads and how many reads per sample you like to include. This allows us to run NanoClass2 in two modes:\n\nWith subsampling: Use this, if you want to compare several classifiers on a smaller subsample of your data. We can subsample our data, by setting using skip: false in the subsample section of the yaml file. If you use this mode, you could also consider to only analyse a subset of your samples, to speed up the analysis.\nWithout subsampling: Use this, if you already know what classifier you want to use. We toggle the subsampling off by setting using skip: true in the subsample section of the yaml file.\n\n\n\nIn the example below subsample is enabled and 100 random reads per sample will be included in the analyses.\nsubsample:\n    skip:                          false\n    samplesize:                    100\n    environment:                   \"preprocess.yml\"\nIn this example below we disable subsampling and analyse all our reads.\nsubsample:\n    skip:                          true\n4. Other settings\nFinally, you can change tool specific parameters: If desired, there are several parameters that can be changed by the user, such as the numbers of threads to use for the different tools or the settings used for the read quality filtering (in nanofilt).\n\n\n\n\n\nTo test whether the workflow is defined properly do a dry-run first. To do this, change part of the snakemake command as follows:\n\nProvide the path to where you installed NanoITS afer --s\nProvide the path to the edited config file after --configfile\nProvide the path to where you want snakemake to install all program dependencies after --conda-prefix. We recommend to install these into the folder in which you downloaded NanoITS but you can change this if desired\n\n\n#activate conda environment with your snakemake installation, i.e. \nmamba activate snakemake_nanoclass\n\n#perform a dry-run\nsnakemake --cores 1 \\\n    -s &lt;path_to_NanoClass2_install&gt;/Snakefile \\\n    --configfile config.yaml \\\n    --use-conda --conda-prefix &lt;path_to_NanoClass2_install&gt;/.snakemake/conda \\\n    --nolock --rerun-incomplete -np\n\n\n\n\nIf the dry-run was successful you can run snakemake interactively with the following command. Adjust the cores according to your system.\n\nsnakemake --cores 1 \\\n    -s &lt;path_to_NanoClass2_install&gt;/Snakefile \\\n    --configfile config.yaml \\\n    --use-conda --conda-prefix &lt;path_to_NanoClass2_install&gt;/.snakemake/conda \\\n    --nolock --rerun-incomplete\n\n\n\n\nAfter a successful run, you can create a report with some of the key output files as follows:\n\nsnakemake --report report.html \\\n  --configfile config.yaml \\\n  -s &lt;path_to_NanoITS_install&gt;/Snakefile\n\nThe report includes:\n\nA shematic of the steps executed\nA PDF containing information about the reads after quality filtering. To view the full report, download the file/\nTaxonomic bargraphs for different taxonomic ranks (and classifiers if more than one was used)\nInformation about the run-times for each sample and statistics on the runtimes for each tool/sample\n\nAdditionally, the output folder contains:\n\n`/data//nanofilt: The filtered reads (useful if you want to do something else with these reads)\n&lt;output_dir&gt;/classifications/&lt;run&gt;/&lt;method&gt;: The OTU matrix for each sample and classifier\n`/tables: OTU and taxonomy tables combined for each sample and classifier used"
  },
  {
    "objectID": "source/run_nanoclass.html#running-nanoclass2-1",
    "href": "source/run_nanoclass.html#running-nanoclass2-1",
    "title": "Running NanoClass2",
    "section": "",
    "text": "To test whether the workflow is defined properly do a dry-run first. To do this, change part of the snakemake command as follows:\n\nProvide the path to where you installed NanoITS afer --s\nProvide the path to the edited config file after --configfile\nProvide the path to where you want snakemake to install all program dependencies after --conda-prefix. We recommend to install these into the folder in which you downloaded NanoITS but you can change this if desired\n\n\n#activate conda environment with your snakemake installation, i.e. \nmamba activate snakemake_nanoclass\n\n#perform a dry-run\nsnakemake --cores 1 \\\n    -s &lt;path_to_NanoClass2_install&gt;/Snakefile \\\n    --configfile config.yaml \\\n    --use-conda --conda-prefix &lt;path_to_NanoClass2_install&gt;/.snakemake/conda \\\n    --nolock --rerun-incomplete -np\n\n\n\n\nIf the dry-run was successful you can run snakemake interactively with the following command. Adjust the cores according to your system.\n\nsnakemake --cores 1 \\\n    -s &lt;path_to_NanoClass2_install&gt;/Snakefile \\\n    --configfile config.yaml \\\n    --use-conda --conda-prefix &lt;path_to_NanoClass2_install&gt;/.snakemake/conda \\\n    --nolock --rerun-incomplete\n\n\n\n\nAfter a successful run, you can create a report with some of the key output files as follows:\n\nsnakemake --report report.html \\\n  --configfile config.yaml \\\n  -s &lt;path_to_NanoITS_install&gt;/Snakefile\n\nThe report includes:\n\nA shematic of the steps executed\nA PDF containing information about the reads after quality filtering. To view the full report, download the file/\nTaxonomic bargraphs for different taxonomic ranks (and classifiers if more than one was used)\nInformation about the run-times for each sample and statistics on the runtimes for each tool/sample\n\nAdditionally, the output folder contains:\n\n`/data//nanofilt: The filtered reads (useful if you want to do something else with these reads)\n&lt;output_dir&gt;/classifications/&lt;run&gt;/&lt;method&gt;: The OTU matrix for each sample and classifier\n`/tables: OTU and taxonomy tables combined for each sample and classifier used"
  },
  {
    "objectID": "source/run_nanoclass.html#edit-the-configuration-file",
    "href": "source/run_nanoclass.html#edit-the-configuration-file",
    "title": "Running NanoClass2",
    "section": "",
    "text": "In the configuration file, also called config.yaml, you can specify how NanoClass2 should be run.\nTo change the default settings and tell Snakemake where your data is located copy the config.yaml file found in the NanoClass2 folder to the folder in which you want to analyse your data, i.e. like this:\n\ncp &lt;path_to_NanoClass2_folder&gt;.config.yaml .\n\nYou can of course run your analyses in NanoITS folder you downloaded, but often its easier to separate software from analyses.\nNext, open the config.yaml with an editor, such as nano. There are several things you can modify:\n1. The samples you want to analyse\nHere, you need to provide the path to a comma-separated mapping file that describes the samples you want to analyse in the section: samples_file: \"example_files/mapping.csv\". You can provide the relative path (i.e. relative to the working directory you start the snakemake workflow in) or absolute path (i.e. the location of a file or directory from the root directory(/))\nThis file needs to contain the following columns:\n\nrun: The run name of your sample. This is useful if you want to run NanoClass several times on the same data but with different settings.\nsample: The names of your sample. This id will be used to label all files created in subsequent steps. Your sample names should be unique and only contain letters and numbers. Do not use other symbols, such as spaces, dots or underscores in your sample names.\nbarcode: The barcode ID. Can be empty as it is not actively used in the workflow as of now\npath: Path to the fastq.gz files. You can provide the relative or absolute path. The workflow accepts one file per barcode, so if you have more than one file merge these files first, for example using the cat command.\n\nAn example file could look like this (exchange  with the location of your samples):\nrun,sample,barcode,path\ndemo,R1A,BC01,&lt;path&gt;/barcode01_merged.fastq.gz\ndemo,R2A,BC02,&lt;path&gt;/barcode02_merged.fastq.gz\ndemo,R3A,BC03,&lt;path&gt;/barcode03_merged.fastq.gz\n2. The classifiers you want to use\nYou can choose what classifiers you want to use in methods: [\"blastn\",\"centrifuge\",\"dcmegablast\",\"idtaxa\",\"megablast\",\"minimap\",\"mothur\",\"qiime\",\"rdp\",\"spingo\"]. If you want to first compare different classifiers you can keep use the full list.\n3. Subsampling our reads\n\n\n\n\n\n\nImportant\n\n\n\nIn this section, we can specify whether we would like to subset the number of reads and how many reads per sample you like to include. This allows us to run NanoClass2 in two modes:\n\nWith subsampling: Use this, if you want to compare several classifiers on a smaller subsample of your data. We can subsample our data, by setting using skip: false in the subsample section of the yaml file. If you use this mode, you could also consider to only analyse a subset of your samples, to speed up the analysis.\nWithout subsampling: Use this, if you already know what classifier you want to use. We toggle the subsampling off by setting using skip: true in the subsample section of the yaml file.\n\n\n\nIn the example below subsample is enabled and 100 random reads per sample will be included in the analyses.\nsubsample:\n    skip:                          false\n    samplesize:                    100\n    environment:                   \"preprocess.yml\"\nIn this example below we disable subsampling and analyse all our reads.\nsubsample:\n    skip:                          true\n4. Other settings\nFinally, you can change tool specific parameters: If desired, there are several parameters that can be changed by the user, such as the numbers of threads to use for the different tools or the settings used for the read quality filtering (in nanofilt)."
  },
  {
    "objectID": "source/references.html",
    "href": "source/references.html",
    "title": "References",
    "section": "",
    "text": "References\nThe version numbers are the exact versions used to develop this workflow.\n\nSnakemake v6.8.0 (Mölder et al. 2021)\nPython v3.9.7\n\nnumpy v1.26.2\ntabulate v0.8\nbiopython==1.78\n\nR v4.0\n\nr-rlang v1.0.5\nr-base v4.0.5\nr-essentials v1.7.0\nphyloseq v1.34 (McMurdie and Holmes 2013)\ndada2 v1.18.0\nseqinr v4.2_16\ndecipher v2.18.1\nr-vroom v1.5.7\n\nPorechop v0.2.4\nNanoFilt v2.7.1\nNanoStat v1.4.0\nseqtk v1.3\nPistis v0.3.3\nblast v2.10.1\nfasta-splitter v0.2.6\nminimap2 v2.17 (Li 2018)\nsamtools v1.10\ncentrifuge v1.0.4_beta\nmothur v1.44\nkraken2 v2.0.8_beta\nqiime2 v2020.8\nspingo=1.3\n\n\n\n\n\n\nReferences\n\nLi, Heng. 2018. “Minimap2: Pairwise Alignment for Nucleotide Sequences.” Bioinformatics 34 (18): 3094–3100. https://doi.org/10.1093/bioinformatics/bty191.\n\n\nMcMurdie, Paul J., and Susan Holmes. 2013. “Phyloseq: An R Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.” PLOS ONE 8 (4): e61217. https://doi.org/10.1371/journal.pone.0061217.\n\n\nMölder, Felix, Kim Philipp Jablonski, Brice Letcher, Michael B. Hall, Christopher H. Tomkins-Tinch, Vanessa Sochat, Jan Forster, et al. 2021. “Sustainable Data Analysis with Snakemake.” F1000Research 10 (April): 33. https://doi.org/10.12688/f1000research.29032.2."
  }
]